---
title: "Structure of Laura's teaching manifesto (v2)"
authors: Laura Pankratz, Elizabeth Pankratz
date: today
format: 
  html:
    toc: true
---

## Part I: What is learning?

Learning is the process of building a consistent response to a stimulus.

Learning is a **cognitive process** (Part II) with certain **behavioural outcomes** (Part III).


Frameworks/taxonomies for talking about learning:

- Bloom's taxonomy
- SOLO (preferred)

The learner is at the centre.


## Part II: The cognitive process of learning, and how we can facilitate it

Learning is messy.

Learning takes energy.

Learning happens by doing.

- Overview of some activities to do in the classroom, with nod to Teaching Science PI resource


Things to think about when interacting with students:

- Respect the student.
- Build and nurture students' trust in you.
- Welcome and listen to questions from students.
- Be intentional about the questions you ask students.


Things to think about when designing and running a course:

- Know why you're including each piece of material.
- Avoid silo-ing by
  - interleaving material and
  - velcro teaching.



## Part III: The behavioural outcomes of learning, and how we can assess them

Assessment is about checking in on how students are doing.
Thus assessment should be happening all the time.

Things to think about when designing (formative or summative) assessments:

- Debunk assumption that % correct answers = % material that somebody knows.
- An assessment should not penalise a student for a particular mistake more than once.
- Assessment should be fair, reliable, and valid.
- Assuming the goal of an assessment is to generate a ranking of students, then the task of the test designer is to produce questions that discriminate well between students.
- Blueprinting a test using a 2D matrix of content * cognitive level.


Things to think about when designing any test question:

- Make sure the question is absolutely clear. Tell students exactly what their task is.
- Ask the question in the format that makes sense for that content.
- The right measure for "is a question good" is "does the question discriminate well", not "do students perform well on this question".



Things to think about when designing multiple choice questions:

- Easier than student-generated response (but the consequent higher rate of success doesn't mean students know more!)
- The top students should be able to read the stem, have an answer, and go hunting for that answer.
- What MC questions are actually testing is the information that the test-taker draws on to choose between the options.
- Nod to some item response theory resources on IIC, p diff, etc.


Things to think about when designing student-generated response questions:

- Can span many possible kinds of response.
- Harder than multiple choice because it forces production with no clues beyond the prompt.
- Standards should differ depending on whether item was produced under duress or not.
- Students should be familiar with scoring criteria before and during response.


Formative assessment is good.

- Overview of a few possibilities (MC with certainty ratings, peer feedback, responding with colour-coded highlights)


Summative assessment is necessary.

- No more learning after grades are delivered.
- Dichotomous vs. partial marks.
- Things to think about when building and using scoring rubrics.
  - n categories maps to ease of pass
  - qualitative descriptions should focus on what's present, not what's absent

